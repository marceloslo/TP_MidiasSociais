{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b03e4940",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import json"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "e80f4257",
   "metadata": {},
   "outputs": [],
   "source": [
    "#get original data\n",
    "videos = pd.read_json('./Data/video_metadata.jsonl',lines=True,encoding='utf-8')\n",
    "with open('./Data/categories.json') as file:\n",
    "    categories = json.load(file)\n",
    "channels = pd.read_json('./Data/channel_metadata.jsonl',lines=True,encoding='utf-8')\n",
    "comments = pd.read_json('./Data/comments.jsonl',lines=True,encoding='utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "5e3e2e8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "videos_from_channels= pd.read_json('./Data/video_metadata_from_channels.jsonl',lines=True,encoding='utf-8')\n",
    "unified_videos = pd.concat([videos,videos_from_channels])\n",
    "unified_videos = unified_videos[unified_videos['category']!='from_channel']\n",
    "unified_videos = unified_videos[unified_videos['category'].astype(int)<30].drop_duplicates('videoId')\n",
    "with open('./Data/complete_videos_metadata.jsonl','w',encoding='utf-8') as file:\n",
    "    for line in unified_videos.to_dict(orient='records'):\n",
    "        json.dump(line,file,ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "52558e17",
   "metadata": {},
   "outputs": [],
   "source": [
    "#exclude undesirable categories are no category and any with id higher than movies\n",
    "comments = pd.merge(comments,unified_videos[['videoId','category']],on='videoId')#.to_dict(orient='records')\n",
    "comments = comments.drop_duplicates('id').to_dict(orient='records')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "58853f6d",
   "metadata": {},
   "outputs": [],
   "source": [
    "with open('./Data/complete_comments.jsonl','w',encoding='utf-8') as file:\n",
    "    for line in comments:\n",
    "        json.dump(line,file,ensure_ascii=False)\n",
    "        file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b3ffa5cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "for chunk in pd.read_json('./Data/comments_from_channels.jsonl',encoding='utf-8',chunksize=10**6,lines=True):\n",
    "    chunk = pd.merge(chunk,unified_videos[['videoId','category']],on='videoId')\n",
    "    chunk = chunk.drop_duplicates('id').to_dict(orient='records')\n",
    "    with open('./Data/complete_comments.jsonl','a',encoding='utf-8') as file:\n",
    "        for line in chunk:\n",
    "            json.dump(line,file,ensure_ascii=False)\n",
    "            file.write('\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "177c1b8a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
